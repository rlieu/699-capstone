{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "179d9479",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\qfu88\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\qfu88\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\qfu88\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09a64d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created at: jobs_full.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open('jobs.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "\n",
    "csv_file_path = 'jobs_full.csv'\n",
    "\n",
    "\n",
    "if data:\n",
    "    fieldnames = list(data[0].keys())\n",
    "\n",
    "\n",
    "with open(csv_file_path, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "   \n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    \n",
    "   \n",
    "    writer.writeheader()\n",
    "    \n",
    "  \n",
    "    for item in data:\n",
    "        writer.writerow(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29684940",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('jobs_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed3cd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'author_flair_text', 'clicked', 'created_utc',\n",
       "       'distinguished', 'edited', 'id', 'is_original_content', 'is_self',\n",
       "       'link_flair_template_id', 'link_flair_text', 'locked', 'name',\n",
       "       'num_comments', 'over_18', 'permalink', 'saved', 'score', 'spoiler',\n",
       "       'stickied', 'text', 'title', 'upvote_ratio', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd90afc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>clicked</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>is_original_content</th>\n",
       "      <th>is_self</th>\n",
       "      <th>link_flair_template_id</th>\n",
       "      <th>...</th>\n",
       "      <th>over_18</th>\n",
       "      <th>permalink</th>\n",
       "      <th>saved</th>\n",
       "      <th>score</th>\n",
       "      <th>spoiler</th>\n",
       "      <th>stickied</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1.709510e+09</td>\n",
       "      <td>moderator</td>\n",
       "      <td>False</td>\n",
       "      <td>1b5wc20</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>169d3732-5d76-11ea-8708-0e8ff3ab2fbd</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>/r/jobs/comments/1b5wc20/success_and_disappoin...</td>\n",
       "      <td>False</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>This is the weekly success and disappointment...</td>\n",
       "      <td>Success and Disappointment Megathread for the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/jobs/comments/1b5wc20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          author author_flair_text  clicked   created_utc distinguished  \\\n",
       "0  AutoModerator               NaN    False  1.709510e+09     moderator   \n",
       "\n",
       "  edited       id  is_original_content  is_self  \\\n",
       "0  False  1b5wc20                False     True   \n",
       "\n",
       "                 link_flair_template_id  ... over_18  \\\n",
       "0  169d3732-5d76-11ea-8708-0e8ff3ab2fbd  ...   False   \n",
       "\n",
       "                                           permalink  saved  score  spoiler  \\\n",
       "0  /r/jobs/comments/1b5wc20/success_and_disappoin...  False      8    False   \n",
       "\n",
       "  stickied                                               text  \\\n",
       "0     True   This is the weekly success and disappointment...   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0  Success and Disappointment Megathread for the ...           1.0   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/jobs/comments/1b5wc20...  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d5c8573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10251759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 659 entries, 0 to 658\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   author                  659 non-null    object \n",
      " 1   author_flair_text       2 non-null      object \n",
      " 2   clicked                 659 non-null    bool   \n",
      " 3   created_utc             659 non-null    float64\n",
      " 4   distinguished           2 non-null      object \n",
      " 5   edited                  659 non-null    object \n",
      " 6   id                      659 non-null    object \n",
      " 7   is_original_content     659 non-null    bool   \n",
      " 8   is_self                 659 non-null    bool   \n",
      " 9   link_flair_template_id  659 non-null    object \n",
      " 10  link_flair_text         659 non-null    object \n",
      " 11  locked                  659 non-null    bool   \n",
      " 12  name                    659 non-null    object \n",
      " 13  num_comments            659 non-null    int64  \n",
      " 14  over_18                 659 non-null    bool   \n",
      " 15  permalink               659 non-null    object \n",
      " 16  saved                   659 non-null    bool   \n",
      " 17  score                   659 non-null    int64  \n",
      " 18  spoiler                 659 non-null    bool   \n",
      " 19  stickied                659 non-null    bool   \n",
      " 20  text                    613 non-null    object \n",
      " 21  title                   659 non-null    object \n",
      " 22  upvote_ratio            659 non-null    float64\n",
      " 23  url                     659 non-null    object \n",
      "dtypes: bool(8), float64(2), int64(2), object(12)\n",
      "memory usage: 87.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "288ee4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['author_flair_text', 'distinguished'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90af7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28fa9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['clicked', 'is_self', 'link_flair_template_id', 'locked', 'saved', 'spoiler', 'stickied']\n",
    "\n",
    "\n",
    "df = df.drop(columns=columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cac34cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 613 entries, 0 to 658\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   author               613 non-null    object \n",
      " 1   created_utc          613 non-null    float64\n",
      " 2   edited               613 non-null    object \n",
      " 3   id                   613 non-null    object \n",
      " 4   is_original_content  613 non-null    bool   \n",
      " 5   link_flair_text      613 non-null    object \n",
      " 6   name                 613 non-null    object \n",
      " 7   num_comments         613 non-null    int64  \n",
      " 8   over_18              613 non-null    bool   \n",
      " 9   permalink            613 non-null    object \n",
      " 10  score                613 non-null    int64  \n",
      " 11  text                 613 non-null    object \n",
      " 12  title                613 non-null    object \n",
      " 13  upvote_ratio         613 non-null    float64\n",
      " 14  url                  613 non-null    object \n",
      "dtypes: bool(2), float64(2), int64(2), object(9)\n",
      "memory usage: 68.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b99ab8",
   "metadata": {},
   "source": [
    "### Specific Cleaning and Preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbcebac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#process created_utc\n",
    "\n",
    "# Convert 'created_utc' to a datetime column\n",
    "df['created_datetime'] = pd.to_datetime(df['created_utc'], unit='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92bae19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"created_utc\" feature engineering\n",
    "df['day_of_week'] = df['created_datetime'].dt.day_name()\n",
    "df['hour_of_day'] = df['created_datetime'].dt.hour\n",
    "df['month'] = df['created_datetime'].dt.month_name()\n",
    "df['year'] = df['created_datetime'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce4bfd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transformation \"edited\"\n",
    "\n",
    "df['was_edited'] = df['edited'].apply(lambda x: False if x == False else True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac4b4ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qfu88\\AppData\\Local\\Temp\\ipykernel_21944\\300110012.py:1: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  df['edit_datetime'] = pd.to_datetime(df['edited'].apply(lambda x: x if x != False else None), unit='s', errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['edit_datetime'] = pd.to_datetime(df['edited'].apply(lambda x: x if x != False else None), unit='s', errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07e07921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in 'is_original_content': [False]\n",
      "Unique values in 'over_18': [False]\n"
     ]
    }
   ],
   "source": [
    "print(df['is_original_content'].unique())\n",
    "print( df['over_18'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12ae44bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['is_original_content', 'over_18'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0f7732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def basic_text_cleaning(df):\n",
    "  \n",
    "    \n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    html_pattern = r'<.*?>'\n",
    "    \n",
    "   \n",
    "    df = df[~df['text'].isin(['[deleted]', '[removed]'])]\n",
    "        \n",
    "    # remove URLs\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(url_pattern, '', str(x)))\n",
    "        \n",
    "    # remove HTML tags\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(html_pattern, '', str(x)))\n",
    "        \n",
    "    #whitespace\n",
    "    df['text'] = df['text'].apply(lambda x: ' '.join(str(x).split()))\n",
    "        \n",
    "    # drop rows with very short responses\n",
    "    df = df[df['text'].apply(lambda x: len(str(x)) > 3)]\n",
    "        \n",
    "    return df\n",
    "\n",
    "# Apply the cleaning function to your DataFrame\n",
    "df = basic_text_cleaning(df)\n",
    "df.to_csv('Job_Datasets/df_minimal_cleaning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "146efeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# preprocessing function:\n",
    "def preprocess_text(text):\n",
    "   \n",
    "    # remove special characters, punctuation, and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # tokenize and lemmatize the text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if token.text not in stopwords.words('english')]\n",
    "    # join the tokens back into a string\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8702fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf198a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Job_Datasets/df_nlp_processing.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f0bda26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>edited</th>\n",
       "      <th>id</th>\n",
       "      <th>link_flair_text</th>\n",
       "      <th>name</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>permalink</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "      <th>created_datetime</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>was_edited</th>\n",
       "      <th>edit_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.709510e+09</td>\n",
       "      <td>False</td>\n",
       "      <td>1b5wc20</td>\n",
       "      <td>Weekly Megathread</td>\n",
       "      <td>t3_1b5wc20</td>\n",
       "      <td>52</td>\n",
       "      <td>/r/jobs/comments/1b5wc20/success_and_disappoin...</td>\n",
       "      <td>8</td>\n",
       "      <td>this weekly success disappointment Megathread ...</td>\n",
       "      <td>Success and Disappointment Megathread for the ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/jobs/comments/1b5wc20...</td>\n",
       "      <td>2024-03-04 00:00:17</td>\n",
       "      <td>Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>March</td>\n",
       "      <td>2024</td>\n",
       "      <td>True</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author   created_utc edited       id    link_flair_text        name  \\\n",
       "0  AutoModerator  1.709510e+09  False  1b5wc20  Weekly Megathread  t3_1b5wc20   \n",
       "\n",
       "   num_comments                                          permalink  score  \\\n",
       "0            52  /r/jobs/comments/1b5wc20/success_and_disappoin...      8   \n",
       "\n",
       "                                                text  \\\n",
       "0  this weekly success disappointment Megathread ...   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0  Success and Disappointment Megathread for the ...           1.0   \n",
       "\n",
       "                                                 url    created_datetime  \\\n",
       "0  https://www.reddit.com/r/jobs/comments/1b5wc20... 2024-03-04 00:00:17   \n",
       "\n",
       "  day_of_week  hour_of_day  month  year  was_edited edit_datetime  \n",
       "0      Monday            0  March  2024        True           NaT  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "168cb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the original columns that have been processed\n",
    "df.drop(columns=['created_utc', 'edited'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67c2daca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(max_df=0.95, min_df=2, max_features=1000)\n",
    "\n",
    "# apply it to preprocessed text\n",
    "tfidf_matrix = tfidf_vect.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ab9b260d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse.save_npz(\"Job_Datasets/tfidf_matrix.npz\", tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831afc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
