{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "069ab571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n",
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     An existing connection was forcibly closed by the\n",
      "[nltk_data]     remote host>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [WinError 10054] An\n",
      "[nltk_data]     existing connection was forcibly closed by the remote\n",
      "[nltk_data]     host>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bd51c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\qfu88\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdf0a7",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d397a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # remove special characters, punctuation, and numbers\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    # lemmatize and remove stopwords\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords.words('english')]\n",
    "    # join the tokens back into a string\n",
    "    return ' '.join(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec726b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Job_Datasets/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f35b2ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8758 entries, 0 to 8757\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      7897 non-null   float64\n",
      " 1   text                    8758 non-null   object \n",
      " 2   title                   8758 non-null   object \n",
      " 3   author                  8648 non-null   object \n",
      " 4   num_comments            8758 non-null   int64  \n",
      " 5   post_id                 8758 non-null   object \n",
      " 6   upvote_ratio            8758 non-null   float64\n",
      " 7   score                   8758 non-null   int64  \n",
      " 8   url                     8758 non-null   object \n",
      " 9   subreddit               8758 non-null   object \n",
      " 10  link_flair_text         8758 non-null   object \n",
      " 11  link_flair_template_id  8758 non-null   object \n",
      " 12  created_datetime        8758 non-null   object \n",
      " 13  day_of_week             8758 non-null   object \n",
      " 14  hour_of_day             8758 non-null   int64  \n",
      " 15  month                   8758 non-null   object \n",
      " 16  year                    8758 non-null   int64  \n",
      "dtypes: float64(2), int64(4), object(11)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39d4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'id' column\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "# Dropping rows with missing values in the 'author' column\n",
    "df = df.dropna(subset=['author'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "639f1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b7096c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text\n",
       "xBnn                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 46\n",
       "Title                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                11\n",
       "Please use thread chat casual discussion ask casual question Moderation light dont jerknnThis thread posted every day midnight PST Previous Daily Chat Threads found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  8\n",
       "Please use thread discussion Big N question related Big N one offer best doggy benefit many company Big N really Posts focusing solely Big N created outside thread probably removednnThere toplevel comment generally recognized Big N company please post appropriate one Theres also Other option flexibility sake want discus company feel sufficiently Big Nlike eg Uber Airbnb Dropbox etcnnAbide rule dont jerknnThis thread posted Sunday Wednesday midnight PST Previous Big N Discussion thread found                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       3\n",
       "This safe place discus current salary compensation package nnKey thing keep mind discussing salarynn Separate Base Salary Total Compensationn Provide regional context Cost Livingn Keep civil constructivennSome helpful link salary resourcesnn Salaries Indeedcom n Glassdoor n Levelsfyi nnMOD NOTE This weekly post                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              3\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ..\n",
       "For background story I still working trying find new role friend recommended apply position referral program pretty huge company So I managed get interview came take home assignment three question specific software I never touched I explained initial call asked I well versed application Then I need present interview next week I actually accepted interview knowing question would like since I told I never use softwarennI tried one task take lot time hour even figure basic alone question complicated problem I full time job senior software engineer oncall support office hour week I install study new unfamiliar application work around I seriously reconsidering withdraw application I simply time itnnI feel tired feel like free labor I take one two hour technical test way much I dont know I try I lost confidence I dont even know still proceed pick interview knowing I listed skill I clearly communicate I experience needed nnnn                                                  1\n",
       "Post post people trying avoid performing Tier Level Helpdesk rolennIf something deal breaker donut join fieldnnI worked IT almost year yes customer facing department My team either face voice IT We represent team within IT get yelled cursed harassed Yet laugh opportunity better connection Experience customer facing department provides perspective thing impact customer base folk donut go Level role donut understandnnI started IT entire team four people employee company wasnut Helpdesk desktop support team let alone dozen team find large company The three u guy took care everything figured stuff Since Iuve worked company small large k end user In EVERY organization customer need taken care EVERYONE IT need engaged solve issuennI seen hundred IT professional never worked Tier donut engage naturally management get involved get working issue refuse document thing                                                                                                                1\n",
       "Ive reading endless thread IT IT career Im trying figure Im right thingnnSince September Ive looking new career I previous experience retail office support dad landscaping business working caregiver special need brother help mom nnIve trying get job working home I dont want deal retail ever Im terrible sale dont tact line work somewhere along way I came across cybersecurity I researching career option I ended I feel like I kiss dream working home goodbye Ive seen thread continuous rejection email place I applied tonnIve working Google coursera certification course cybersecurity get enough experience start sort entry level job Im sure video course people talking easy get foot door tech role real theyre playing keep people going finish course Is real I looking outdated data nnThe course bit tedious easy enough I know I dont enough experience Im trying work skillsnSorry place This first time Ive tried organize thought feeling point Im trying get job survive nnTIA nn     1\n",
       "My company letting pick old equipment taking recycled I want start homelab learn server Linux skill become SysAdmin What I keep nnEquipment n x port switch port switchn multiple router voice switchesn multiple old inGate SonicWall firewallsn old tower Dell Optiplex model                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       1\n",
       "I subbed today th th grade teacher Ium exaggerating I say least student nd grade reading level The student spend class time filling ucall meud worksheet whatus name favorite color favorite food etc I asked time today ucwhat wordud Movie Excited Trait ucHow I spell race car driverud nnHoly horrifying Batman How many parent ok Also passed rd th th th grade nnIs normal kiddos getting shit end stick public school low income neighborhood                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1\n",
       "Name: count, Length: 8480, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe953ae6",
   "metadata": {},
   "source": [
    "### further cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b3bd60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['text'].str.contains('xBnn|Title|^Please use thread|^ReadOnly Friday', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38d81d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7852, 16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a62115d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7852 entries, 0 to 8757\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   text                    7852 non-null   object \n",
      " 1   title                   7852 non-null   object \n",
      " 2   author                  7852 non-null   object \n",
      " 3   num_comments            7852 non-null   int64  \n",
      " 4   post_id                 7852 non-null   object \n",
      " 5   upvote_ratio            7852 non-null   float64\n",
      " 6   score                   7852 non-null   int64  \n",
      " 7   url                     7852 non-null   object \n",
      " 8   subreddit               7852 non-null   object \n",
      " 9   link_flair_text         7852 non-null   object \n",
      " 10  link_flair_template_id  7852 non-null   object \n",
      " 11  created_datetime        7852 non-null   object \n",
      " 12  day_of_week             7852 non-null   object \n",
      " 13  hour_of_day             7852 non-null   int64  \n",
      " 14  month                   7852 non-null   object \n",
      " 15  year                    7852 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(11)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a58ee0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='text', keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a126017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7761, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d0a51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7761 entries, 0 to 8757\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   text                    7761 non-null   object \n",
      " 1   title                   7761 non-null   object \n",
      " 2   author                  7761 non-null   object \n",
      " 3   num_comments            7761 non-null   int64  \n",
      " 4   post_id                 7761 non-null   object \n",
      " 5   upvote_ratio            7761 non-null   float64\n",
      " 6   score                   7761 non-null   int64  \n",
      " 7   url                     7761 non-null   object \n",
      " 8   subreddit               7761 non-null   object \n",
      " 9   link_flair_text         7761 non-null   object \n",
      " 10  link_flair_template_id  7761 non-null   object \n",
      " 11  created_datetime        7761 non-null   object \n",
      " 12  day_of_week             7761 non-null   object \n",
      " 13  hour_of_day             7761 non-null   int64  \n",
      " 14  month                   7761 non-null   object \n",
      " 15  year                    7761 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(11)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a516bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Sentiment & Engagement Datasets/ready_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a1a1ff",
   "metadata": {},
   "source": [
    "### Performing Sentiment Analysis with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdb5fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
