{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dross\\Desktop\\Project\\venv\\Lib\\site-packages\\tpot\\builtins\\__init__.py:36: UserWarning: Warning: optional dependency `torch` is not available. - skipping import of NN models.\n",
      "  warnings.warn(\"Warning: optional dependency `torch` is not available. - skipping import of NN models.\")\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dross\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dross\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dross\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\dross\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from pmdarima.arima import auto_arima\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.api import VAR\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from tqdm import tqdm\n",
    "#import itertools\n",
    "from pandas.plotting import parallel_coordinates\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesClassifier,RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tpot import TPOTClassifier\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from tpot.builtins import StackingEstimator\n",
    "from tpot.export_utils import set_param_recursive\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from typing import List\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "import nltk\n",
    "import pickle as pickle \n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "import spacy as spacy \n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import spacy\n",
    "from spacytextblob.spacytextblob import SpacyTextBlob\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('spacytextblob')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCALLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # condense into one df \n",
    "# df1 = pd.read_csv('C:/Users/dross/Desktop/Project/aspergers.csv', parse_dates=True)\n",
    "# df2 = pd.read_csv('C:/Users/dross/Desktop/Project/depression.csv', parse_dates=True)\n",
    "# df3 = pd.read_csv('C:/Users/dross/Desktop/Project/ocd.csv', parse_dates=True)\n",
    "# df4 = pd.read_csv('C:/Users/dross/Desktop/Project/ptsd.csv', parse_dates=True)\n",
    "# df5 = pd.read_csv('C:/Users/dross/Desktop/Project/adhd.csv', parse_dates=True)\n",
    "\n",
    "# df = pd.concat([df1, df2, df3, df4,df5], ignore_index=True)\n",
    "# #LOWER ALL subreddit \n",
    "# df['subreddit'] = df['subreddit'].str.lower()\n",
    "# #df.to_csv('Sentiment.csv',index=False)\n",
    "# #wondered if removing nans improve model performance \n",
    "# df = df.dropna(subset=['body'])\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149679, 10)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # condense into one df \n",
    "df1 = pd.read_csv('Datasets/aspergers.csv', parse_dates=True)\n",
    "df2 = pd.read_csv('Datasets/depression.csv', parse_dates=True)\n",
    "df3 = pd.read_csv('Datasets/ocd.csv', parse_dates=True)\n",
    "df4 = pd.read_csv('Datasets/ptsd.csv', parse_dates=True)\n",
    "df5 = pd.read_csv('Datasets/adhd.csv', parse_dates=True)\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4,df5], ignore_index=True)\n",
    "#LOWER ALL subreddit \n",
    "df['subreddit'] = df['subreddit'].str.lower()\n",
    "df = df.dropna(subset=['body'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Will be using the Vader sentiment analysis tested out amongst the other packages vader is best for social media data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"body\"].isin([\"[deleted]\", \"[removed]\"])]\n",
    "df = df[df[\"body\"].str.len() > 2]\n",
    "df['body'] = df['body'].replace(to_replace=r'http\\S+|www.\\S+', value='', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## continue cleaning\n",
    "\n",
    "# remove specific structured placeholders\n",
    "df['body'] = df['body'].replace(to_replace=r'\\[deleted\\]\\n\\n\\[View Poll\\]', value='', regex=True)\n",
    "\n",
    "# remove markdown and keep only the descriptive text\n",
    "df['body'] = df['body'].replace(to_replace=r'\\[([^\\]]+)\\]\\([^)]*\\)', value=r'\\1', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "df['body'] = df['body'].str.strip()  #whitespace\n",
    "df = df[df['body'] != '']  # remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## further cleaning\n",
    "# remove more specific structured placeholders\n",
    "df['body'] = df['body'].replace(to_replace=r'\\[removed\\].*?\\[View Poll\\]\\(', value='', regex=True)\n",
    "df['body'] = df['body'].replace(to_replace=r'\\[.*?\\]\\(.*?\\)', value='', regex=True)  \n",
    "df['body'] = df['body'].replace(to_replace=r'\\[|\\]', value='', regex=True)  \n",
    "\n",
    "# remove entries that only consist of punctuation or are extremely short after previous cleanings\n",
    "df['body'] = df['body'].replace(to_replace=r'^\\s*\\W*\\s*$', value='', regex=True)\n",
    "\n",
    "\n",
    "df['body'] = df['body'].str.strip()  # remove whitespace\n",
    "df = df[df['body'] != '']  # remove empty rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize whitespace by replacing multiple spaces with a single space\n",
    "df['body'] = df['body'].apply(lambda x: re.sub(r'\\s+', ' ', x).strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Power of the vader is it works well if we leave stop words and caps cans be used as context so no lowering will take place or removal of stop words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_minimal(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\@\\w+', '', text)  # Remove mentions\n",
    "    return text\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Minimal cleaning\n",
    "df['clean_body'] = df['body'].apply(clean_text_minimal)\n",
    "\n",
    "# Apply VADER sentiment analysis\n",
    "df['vader_sentiment'] = df['clean_body'].apply(lambda text: sia.polarity_scores(text)['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>clean_body</th>\n",
       "      <th>vader_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adadum</td>\n",
       "      <td>i wish i could do a poll for this but what wou...</td>\n",
       "      <td>2021-12-23T17:56:36.000Z</td>\n",
       "      <td>rn19yc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>aspergers</td>\n",
       "      <td>Separatism for high-functioning Autists?</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/aspergers/comments/rn...</td>\n",
       "      <td>1</td>\n",
       "      <td>i wish i could do a poll for this but what wou...</td>\n",
       "      <td>0.2144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lazy_Opposite8263</td>\n",
       "      <td>i was diagnosed with high functioning asperger...</td>\n",
       "      <td>2021-12-23T17:53:41.000Z</td>\n",
       "      <td>rn17lw</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>aspergers</td>\n",
       "      <td>Friend blaming toxic behaviour on autism? How ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/aspergers/comments/rn...</td>\n",
       "      <td>1</td>\n",
       "      <td>i was diagnosed with high functioning asperger...</td>\n",
       "      <td>-0.9447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LockedOutOfElfland</td>\n",
       "      <td>it's been a while since i've seen a therapist ...</td>\n",
       "      <td>2021-12-23T17:28:07.000Z</td>\n",
       "      <td>rn0n6k</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>aspergers</td>\n",
       "      <td>Do therapists/mental health professionals misi...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/aspergers/comments/rn...</td>\n",
       "      <td>1</td>\n",
       "      <td>it's been a while since i've seen a therapist ...</td>\n",
       "      <td>-0.9102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PlazmaSkittles</td>\n",
       "      <td>new here. 22 years old. diagnosed at 12. adhd ...</td>\n",
       "      <td>2021-12-23T16:54:23.000Z</td>\n",
       "      <td>rmzvwn</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>aspergers</td>\n",
       "      <td>I think I'm broken</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/aspergers/comments/rm...</td>\n",
       "      <td>1</td>\n",
       "      <td>new here. 22 years old. diagnosed at 12. adhd ...</td>\n",
       "      <td>-0.4454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xime_rollin</td>\n",
       "      <td>based on your understanding</td>\n",
       "      <td>2021-12-23T16:53:43.000Z</td>\n",
       "      <td>rmzvds</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>aspergers</td>\n",
       "      <td>I recently took an eq test and scored 20 out o...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>https://www.reddit.com/r/aspergers/comments/rm...</td>\n",
       "      <td>1</td>\n",
       "      <td>based on your understanding</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                               body  \\\n",
       "0              Adadum  i wish i could do a poll for this but what wou...   \n",
       "1   Lazy_Opposite8263  i was diagnosed with high functioning asperger...   \n",
       "2  LockedOutOfElfland  it's been a while since i've seen a therapist ...   \n",
       "3      PlazmaSkittles  new here. 22 years old. diagnosed at 12. adhd ...   \n",
       "4         xime_rollin                        based on your understanding   \n",
       "\n",
       "                created_utc      id  num_comments  score  subreddit  \\\n",
       "0  2021-12-23T17:56:36.000Z  rn19yc             0      1  aspergers   \n",
       "1  2021-12-23T17:53:41.000Z  rn17lw             1      1  aspergers   \n",
       "2  2021-12-23T17:28:07.000Z  rn0n6k             2      3  aspergers   \n",
       "3  2021-12-23T16:54:23.000Z  rmzvwn             3      1  aspergers   \n",
       "4  2021-12-23T16:53:43.000Z  rmzvds             0      1  aspergers   \n",
       "\n",
       "                                               title  upvote_ratio  \\\n",
       "0           Separatism for high-functioning Autists?           1.0   \n",
       "1  Friend blaming toxic behaviour on autism? How ...           1.0   \n",
       "2  Do therapists/mental health professionals misi...           1.0   \n",
       "3                                 I think I'm broken           1.0   \n",
       "4  I recently took an eq test and scored 20 out o...           1.0   \n",
       "\n",
       "                                                 url  target  \\\n",
       "0  https://www.reddit.com/r/aspergers/comments/rn...       1   \n",
       "1  https://www.reddit.com/r/aspergers/comments/rn...       1   \n",
       "2  https://www.reddit.com/r/aspergers/comments/rn...       1   \n",
       "3  https://www.reddit.com/r/aspergers/comments/rm...       1   \n",
       "4  https://www.reddit.com/r/aspergers/comments/rm...       1   \n",
       "\n",
       "                                          clean_body  vader_sentiment  \n",
       "0  i wish i could do a poll for this but what wou...           0.2144  \n",
       "1  i was diagnosed with high functioning asperger...          -0.9447  \n",
       "2  it's been a while since i've seen a therapist ...          -0.9102  \n",
       "3  new here. 22 years old. diagnosed at 12. adhd ...          -0.4454  \n",
       "4                        based on your understanding           0.0000  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exported sample size of post for external regex validation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
